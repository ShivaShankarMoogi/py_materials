{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"http://www.nasa.gov/sites/all/themes/custom/nasatwo/images/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://github.com/astg606/py_materials/blob/master/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center><h1> <font color=\"red\">Reading OMI hdf5 Files using h5py</font></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Primary References/Resources</font>\n",
    "\n",
    "- [Ozone Monitoring Instrument (OMI)](https://www.earthdata.nasa.gov/learn/find-data/near-real-time/omi)\n",
    "- [h5py Quick Start Guide](https://docs.h5py.org/en/stable/quick.html)\n",
    "- [OMNO2d File Specification](https://docserver.gesdisc.eosdis.nasa.gov/repository/Mission/OMI/3.3_ScienceDataProductDocumentation/3.3.2_ProductRequirements_Designs/OMNO2d_FileSpec_V003.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.xarray\n",
    "from cartopy import crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shapereader\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggles off alphabetical sorting\n",
    "pprint.sorted = lambda x, key=None:x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">What is OMI? </font>\n",
    "\n",
    "- The Ozone Monitoring Instrument (OMI) aboard NASA's Aura satellite (launched in 2004) measures ozone from Earth's surface to top-of-atmosphere. \n",
    "- OMI also measures sulfur dioxide (SO2), aerosols, and cloud top pressure. \n",
    "- Near real-time (NRT) OMI data are available through LANCE generally within three hours after a satellite observation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Accessing a Sample HDF5 Data Files</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Directory where the OMI files are located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/jkouatch/myTasks/PythonTraining/ASTG606/Materials/sat_data/OMI_Data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full path to the file name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.join(data_dir, \"OMI-Aura_L3-OMTO3e_2022m0709_v003-2022m0711t031807.he5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Opening the File</font>\n",
    "\n",
    "Opening file for reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid = h5py.File(file_name, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Hierarchy\n",
    "\n",
    "File -->  Group -->  Sub-group -->  Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `visit()` function returns the hierarchy of the file by utilizing the Python `print()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.visit(print)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can even incorporate `lambda` or use predefined functions to retrieve more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.visit(lambda x: print(x, fid[x], \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve hierarchy and corresponding objects\n",
    "def print_more(name):\n",
    "    print(name, fid[name], \"\\n\")\n",
    "    \n",
    "fid.visit(print_more)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the type of each object, for groups, the number of members and its path is returned. For datasets, the name, shape, and array type is returned instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Data Extraction </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing Groups / Subgroups\n",
    "\n",
    "- Using what we know about the behavior of groups, we can access all objects like dictionaries.\n",
    "\n",
    "We can access group and subgroup keys:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_keys = list(fid.keys())\n",
    "print(fid_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group and subgroup values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_values = list(fid.values())\n",
    "print(fid_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "group and subgroup items,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid_items = dict(fid.items())\n",
    "print(fid_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or we can access the objects within them themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fid['HDFEOS']['ADDITIONAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dict(fid['HDFEOS']['ADDITIONAL']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Information\n",
    "\n",
    "Let's use a the `/HDFEOS/GRIDS/` sub-group as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group = fid['HDFEOS']['GRIDS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can access group names (includes path),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the parent group of a subgroup, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group.parent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the file to which the group belongs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group.file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition, we can access the **attributes** through the `attrs` variable which follows a dictionary-like interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group_attrs = dict(sample_group.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_group_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, this group doesn't have any attributes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Important Application\n",
    "\n",
    "At first glance, it appears that most of the groups and sub-groups in the folder are irrelevant. When looking at the hierarchy, they either lead to the data itself or to other empty sub-groups and datasets.\n",
    "\n",
    "In reality, they may hold crucial information stored as attributes. Luckily, we can take advantage of the `visit()` function to get our \"invisible\" metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_attrs(name):\n",
    "    print(name, \"\\n\\tAttributes:\", fid[name].attrs.keys(), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using a pre-defined function, we can access the attribute keys of every single object in the `HDF5` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.visit(print_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to **file-level attributes** and even **coordinate metadata**, we can access our **dataset attributes** as they, too, use the `attrs` variable to access them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Accessing Top-level Metadata</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File-level Attributes\n",
    "\n",
    "From displaying all attributes above, we can see that file-level attributes are stored as attributes w/in the `HDFEOS/ADDITIONAL/FILE_ATTRIBUTES/` sub-group.\n",
    "\n",
    "Since attributes have a dictionary-like interface in `h5py`, it's simple to obtain them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_attrs = dict( fid['HDFEOS']['ADDITIONAL']['FILE_ATTRIBUTES'].attrs )\n",
    "\n",
    "file_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`h5py` stores the attribute values as `NumPy` data types: `numpy.ndarray` for all numeric and array representations and `numpy.bytes_` for all string and character representations along with tuples and dictionaries.\n",
    "\n",
    "While we could leave them that way, it would definitely be more convenient to convert them into more familiar data types due to their string representations. Thankfully, the `isinstance()` function exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in file_attrs.items():\n",
    "    if isinstance(item, np.ndarray):   # Converts np arrays to a list to, if applicable, an int or float\n",
    "        item = list(item)\n",
    "        \n",
    "        if len(item) == 1:\n",
    "            item = item[0]\n",
    "    elif isinstance(item, np.bytes_):   # Converts np bytes to an np string to a Python string\n",
    "        item = str(item.astype('str'))\n",
    "        \n",
    "        if item[0] == '(' or item[0] == '{':   # Converts to tuple or dict if applicable\n",
    "            item = eval(item)\n",
    "        # **eval() relaiability??**\n",
    "            \n",
    "    file_attrs[key] = item   # Updates any changes to the key value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint.pprint(file_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Coordinates and Plotting Information\n",
    "\n",
    "Our plotting-related metadata seems to be stored as attributes in the `HDFEOS/GRIDS/OMI Column Amount O3` sub-group. We can try to access them the same way as file attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attrs = dict( fid['HDFEOS']['GRIDS']['OMI Column Amount O3'].attrs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the same data type conversion method, we can get more convenient data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in plot_attrs.items():\n",
    "    if isinstance(item, np.ndarray):   # Converts np arrays to a list to, if applicable, an int or float\n",
    "        item = list(item)\n",
    "        \n",
    "        if len(item) == 1:\n",
    "            item = item[0]\n",
    "    elif isinstance(item, np.bytes_):   # Converts np bytes to an np string to a Python string\n",
    "        item = str(item.astype('str'))\n",
    "        \n",
    "        if item[0] == '(' or item[0] == '{':   # Converts to tuple or dict if applicable\n",
    "            item = eval(item)\n",
    "        # **eval() relaiability??**\n",
    "            \n",
    "    plot_attrs[key] = item   # Updates any changes to the key value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These attributes give us all the information we need to construct coordinates need for `XArray` datasets.\n",
    "\n",
    "First, we want to identify our coordinate boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lonW = plot_attrs['GridSpan'][0]\n",
    "lonE = plot_attrs['GridSpan'][1]\n",
    "latS = plot_attrs['GridSpan'][2]\n",
    "latN = plot_attrs['GridSpan'][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we just need to obtain the number of lats and lons in the grid (our dimension sizes), which is also readily available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon_size = plot_attrs['NumberOfLongitudesInGrid']\n",
    "lat_size = plot_attrs['NumberOfLatitudesInGrid']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, using NumPy's `linspace()` function, we can now create our coordinates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = np.linspace(lonW, lonE, lon_size)\n",
    "lats = np.linspace(latS, latN, lat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Longitudes:\\n', lons)\n",
    "print('Latitudes:\\n', lats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Accessing Data Fields and Datasets</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking back at the file layout, we can see that the data appears to be w/in the subgroup `/HDFEOS/GRIDS/OMI Column Amount O3/Data Fields/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group = fid['HDFEOS']['GRIDS']['OMI Column Amount O3']['Data Fields']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take advantage of the `visit()` function once again and get some descriptive information and attributes of each dataset w/in the sub-group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_info(name):\n",
    "    print('Name:', name, \n",
    "          '\\n\\tInfo:', data_group[name],\n",
    "          '\\n\\tAttrs:', data_group[name].attrs.keys(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_group.visit(print_data_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Datasets\n",
    "\n",
    "Given our previous knowledge of reading attributes, accessing important keys such as missing and fill values, scale factors, and offset values will be straightforward.\n",
    "\n",
    "Let's use the `SolarZenithAngle` dataset as our sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds = data_group['SolarZenithAngle']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now examine the attributes more closely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_attrs = dict(sample_ds.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time for our signature data type conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, item in sample_ds_attrs.items():\n",
    "    if isinstance(item, np.ndarray):   # Converts np arrays to a list to, if applicable, an int or float\n",
    "        item = list(item)\n",
    "        \n",
    "        if len(item) == 1:\n",
    "            item = item[0]\n",
    "    elif isinstance(item, np.bytes_):   # Converts np bytes to an np string to a Python string\n",
    "        item = str(item.astype('str'))\n",
    "        \n",
    "        if item[0] == '(' or item[0] == '{':   # Converts to tuple or dict if applicable\n",
    "            item = eval(item)\n",
    "        # **eval() relaiability??**\n",
    "            \n",
    "    sample_ds_attrs[key] = item   # Updates any changes to the key value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can extract our targeted attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values (also a reset if testing different datasets/variables)\n",
    "fill = None\n",
    "scale = 1\n",
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sample_ds_attrs.items():\n",
    "    if key == '_FillValue':\n",
    "        fill = value  \n",
    "    if key == 'ScaleFactor':\n",
    "        scale = value\n",
    "    if key == 'Offset':\n",
    "        offset = value\n",
    "# data = data * scale + offset\n",
    "    \n",
    "print('Fill Value:', fill)\n",
    "print('Scale Factor:', scale)\n",
    "print('Offset:', offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing we need ot do is to access our actual **data**. `h5py` makes this really simple. All we need to do is add `[()]` next to our dataset object and all of it is now in `NumPy` array format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sample_ds[()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Accessing Dimensions</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing to access in our HDF5 file is dataset **dimensions**, known as **dimension scales** in `h5py`.\n",
    "\n",
    "We can access a dataset's dimensions by getting a list of dimension objects using the `dims()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_dims = list(sample_ds.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension objects are simply another `HDF5` dataset. Normally, one would be able to access dimension labels and scales associated with each axis. For our OMI satellite data file, our dimension objects are empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sample_ds_dims[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds_dims[0].label   # would return dimension label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(sample_ds_dims[0].items())   # would return label and scales associated with this axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample_ds_dims[0][0]   # would return scale data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead, we can try to match the dataset shape to our plotting attributes describing lon and lat size to assign our `xarray` dimension names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lon_size, lat_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_ds.shape[0] == lon_size:\n",
    "    sample_ds_dims = ['lon', 'lat']\n",
    "elif sample_ds.shape[0] == lat_size:\n",
    "    sample_ds_dims = ['lat', 'lon']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Configuring the order is important for our `xarray` DataArray initilizations.\n",
    "\n",
    "Now that we've gotten all the information we need, we can close our file reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Conversion to Xarray DataArrays and Datasets</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've been able to get all of the necessary information to create an `xarray` dataset, we can start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fid(filename):\n",
    "# Accessing our file identifier object\n",
    "    '''\n",
    "       Receive amd hdf5 file name, open it and \n",
    "       return the file identifier object.\n",
    "    \n",
    "       Input Parameterd: \n",
    "         - filename (str): file name\n",
    "       Returned value:\n",
    "         - fid: h5py file identifier object\n",
    "    '''\n",
    "    fid = h5py.File(filename, 'r')\n",
    "    return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_group(fid):\n",
    "    '''\n",
    "       Use the file identifier to extract a datafield subgroup.\n",
    "\n",
    "       Input Parameterd: \n",
    "         - fid: h5py file identifier object\n",
    "       Returned value:\n",
    "         - data_group: the data field group (contents) of the file\n",
    "    '''\n",
    "    # contents of our parent group\n",
    "    parent_contents = dict(fid['HDFEOS']['GRIDS']) \n",
    "    # our subparent group object\n",
    "    subparent = list(parent_contents.values())[0]\n",
    "    # contents of our subparent group\n",
    "    subparent_contents = dict(subparent)   \n",
    "    # our data group object\n",
    "    data_group = list(subparent_contents.values())[0]   \n",
    "    \n",
    "    return dict(data_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_dict_dtype(sample_dict):\n",
    "    '''\n",
    "       Converts attribute dictionary from Numpy data types \n",
    "       to general Python data types\n",
    "\n",
    "       Input Parameterd: \n",
    "         - sample_dict: A dictionary of attributes\n",
    "       Returned value:\n",
    "         - sample_dict: A dictionary of attributes\n",
    "    '''\n",
    "    for key, item in sample_dict.items():\n",
    "        if isinstance(item, np.ndarray):   # Converts np arrays to a list to, if applicable, an int or float\n",
    "            item = list(item)\n",
    "        \n",
    "            if len(item) == 1:\n",
    "                item = item[0]\n",
    "        elif isinstance(item, np.bytes_):   # Converts np bytes to an np string to a Python string\n",
    "            item = str(item.astype('str'))\n",
    "        \n",
    "            if item[0] == '(' or item[0] == '{':   # Converts to tuple or dict if applicable\n",
    "                item = eval(item)\n",
    "            # **eval() relaiability??**\n",
    "            \n",
    "        sample_dict[key] = item   # Updates any changes to the key value\n",
    "        \n",
    "    return sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fid_attrs(fid):\n",
    "    \"\"\"\n",
    "       Use the file identified to return the file-level attributes \n",
    "       in the proper data type\n",
    "       \n",
    "       Input Parmeters:\n",
    "         - fid: file identifier\n",
    "       Returned value:\n",
    "         - fid_attrs: a dictionary.\n",
    "    \"\"\"\n",
    "    fid_attrs = dict( fid['HDFEOS']['ADDITIONAL']['FILE_ATTRIBUTES'].attrs )\n",
    "    fid_attrs = convert_dict_dtype(fid_attrs)\n",
    "    \n",
    "    fid_attrs.update(get_plot_attrs(fid))\n",
    "    \n",
    "    return fid_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_plot_attrs(fid):\n",
    "    \"\"\"\n",
    "       Use a file attribute returns the plotting attributes.\n",
    "       \n",
    "       Input Parameters:\n",
    "          - fid: h5py file identifier\n",
    "       Returned value:\n",
    "          - plot_attrs: a dictionatory\n",
    "    \"\"\"\n",
    "    parent_contents = dict(fid['HDFEOS']['GRIDS'])\n",
    "    subgroup = list(parent_contents.values())[0]\n",
    "    \n",
    "    plot_attrs = dict(subgroup.attrs)\n",
    "    plot_attrs = convert_dict_dtype(plot_attrs)\n",
    "    \n",
    "    return plot_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_attrs(ds):\n",
    "    \"\"\"\n",
    "       Give a dataset identifier, return the dataset attribute.\n",
    "       \n",
    "       Input Parameters:\n",
    "          - ds: dataset identifier\n",
    "       Returned value:\n",
    "          - ds_attrs: a dictionary\n",
    "    \"\"\"\n",
    "    ds_attrs = dict(ds.attrs)\n",
    "    ds_attrs = convert_dict_dtype(ds_attrs)\n",
    "    \n",
    "    return ds_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fill(ds_attrs):\n",
    "    \"\"\"\n",
    "       Return the fill value of a given dataset object.\n",
    "       \n",
    "       Input Parameters: \n",
    "          - ds_attrs: A dictionary of dataset attributes\n",
    "       Returned Value: \n",
    "          - value: Either an integer, floating point, or 'None'\n",
    "    \"\"\"\n",
    "    for key, value in ds_attrs.items():\n",
    "        if key == '_FillValue':\n",
    "            return value\n",
    "    return None\n",
    "\n",
    "def get_scale(ds_attrs):\n",
    "    \"\"\"\n",
    "       Return the scale factor of a given dataset object.\n",
    "       \n",
    "       Input Parameters: \n",
    "          - ds_attrs: A dictionary of dataset attributes\n",
    "       Returned Value: \n",
    "          - value: Either an integer, floating point, or 'None'\n",
    "    \"\"\"\n",
    "    for key, value in ds_attrs.items():\n",
    "        if key == 'ScaleFactor':\n",
    "            return value\n",
    "\n",
    "def get_offset(ds_attrs):\n",
    "    \"\"\"\n",
    "       Return the offset value of a given dataset object.\n",
    "       \n",
    "       Input Parameters: \n",
    "          - ds_attrs: A dictionary of dataset attributes\n",
    "       Returned Value: \n",
    "          - value: Either an integer, floating point, or 'None'\n",
    "    \"\"\"\n",
    "    for key, value in ds_attrs.items():\n",
    "        if key == 'Offset':\n",
    "            return value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_data(ds):\n",
    "   '''\n",
    "      Restore the dataset data using the dataset attributes.\n",
    "      \n",
    "      Input Parameters:\n",
    "         - ds: h5py dataset identifier\n",
    "      Returned Value:\n",
    "         - data: numpy array\n",
    "    '''\n",
    "    ds_attrs = get_ds_attrs(ds)\n",
    "    \n",
    "    fill = get_fill(ds_attrs)\n",
    "    scale = get_scale(ds_attrs)\n",
    "    offset = get_offset(ds_attrs)\n",
    "    \n",
    "    data = ds[()]#.astype('float')\n",
    "    \n",
    "    data = np.where(data != fill, data, np.nan)\n",
    "    data *= scale\n",
    "    data += offset\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(fid):\n",
    "    '''\n",
    "       Return the file coordinates given its identifier object.\n",
    "       \n",
    "       Input Parameters:\n",
    "          - fid: h5py file identifier\n",
    "       Returned value:\n",
    "          - dictionary of latitudes and longitudes and Numpy arrays.\n",
    "    '''\n",
    "    plot_attrs = get_plot_attrs(fid)\n",
    "    \n",
    "    lonW = plot_attrs['GridSpan'][0]\n",
    "    lonE = plot_attrs['GridSpan'][1]\n",
    "    latS = plot_attrs['GridSpan'][2]\n",
    "    latN = plot_attrs['GridSpan'][3]\n",
    "    \n",
    "    lon_size = plot_attrs['NumberOfLongitudesInGrid']\n",
    "    lat_size = plot_attrs['NumberOfLatitudesInGrid']\n",
    "    \n",
    "    lons = np.linspace(lonW, lonE, lon_size)\n",
    "    lats = np.linspace(latS, latN, lat_size)\n",
    "    \n",
    "    return {'lons': lons, 'lats': lats}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_dims(ds, coords):\n",
    "    '''\n",
    "       Get dataset dimension names given dataset and coordinates\n",
    "       \n",
    "       Input Parameters:\n",
    "          - ds: a h5py dataset\n",
    "          - coords: a dictionary of coordinates\n",
    "       Returned Value:\n",
    "          - ds_dims: a dctionany\n",
    "   '''\n",
    "    dims = ds.dims\n",
    "    ds_dims = {}\n",
    "    \n",
    "    for i in range(len(dims)):\n",
    "        if dims[i].label == '':\n",
    "            if ds.shape[i] == coords['lons'].size:\n",
    "                ds_dims['lon'] = ds.shape[i]\n",
    "            elif ds.shape[i] == coords['lats'].size:\n",
    "                ds_dims['lat'] = ds.shape[i]\n",
    "        else:\n",
    "            ds_dims[dims[i].label] = ds.shape[i]\n",
    "    \n",
    "    return ds_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coords(dims, coords): \n",
    "    '''\n",
    "       Rearrange coordinates order to match dimensions\n",
    "       shapes for a dataset.\n",
    "       \n",
    "       Input Parameters:\n",
    "          - dims: a dictionary of dimensions\n",
    "          - coords: a dictionary of coordinates\n",
    "       Returned Value:\n",
    "          - coords: a dictionary\n",
    "   '''\n",
    "    if list(dims.values())[0] != list(coords.values())[0].size:\n",
    "        temp = coords\n",
    "        coords = {list(coords.keys())[1]: list(coords.values())[1], \n",
    "                  list(coords.keys())[0]: list(coords.values())[0]}\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filename):\n",
    "    '''\n",
    "       Given an OMI HDF5 file name, convert the data into \n",
    "       an Xarray Dataset.\n",
    "       \n",
    "       Input Parameters:\n",
    "          - filename (str): HDF5 file name containing OMI data\n",
    "       Returned Value:\n",
    "          - xr_ds: an Xarray Dataset\n",
    "    '''\n",
    "    xr_ds = xr.Dataset()\n",
    "    \n",
    "    fid = get_fid(filename)\n",
    "    \n",
    "    data_group = get_data_group(fid)\n",
    "    fid_attrs = get_fid_attrs(fid)   \n",
    "    fid_coords = get_coords(fid)\n",
    "    \n",
    "    for name, hdf_ds in data_group.items():\n",
    "        data = restore_data(hdf_ds)       \n",
    "        ds_attrs = get_ds_attrs(hdf_ds)\n",
    "        \n",
    "        ds_dims = get_ds_dims(hdf_ds, fid_coords)\n",
    "        ds_coords = check_coords(ds_dims, fid_coords)\n",
    "    \n",
    "        xr_ds[name] = xr.DataArray(data, dims = list(ds_dims.keys()), coords = list(ds_coords.values()))\n",
    "        xr_ds[name].attrs = ds_attrs\n",
    "        \n",
    "        \n",
    "    xr_ds.attrs = fid_attrs    \n",
    "       \n",
    "    fid.close()    \n",
    "    return xr_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ds = read_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Plotting Our Data</font>\n",
    "\n",
    "File size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_MB = file_ds.nbytes / 1000000\n",
    "\n",
    "file_MB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = file_ds['RadiativeCloudFraction']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic `matplotlib` plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic `hvPlot` plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More intermediate `hvPlot` plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.hvplot.quadmesh('lon', 'lat', projection = ccrs.PlateCarree(), geo = True, ylim = (-60, 80),\n",
    "                    project = True, cmap = 'blues', rasterize = True, coastline = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var.hvplot.contour('lon', 'lat', projection = ccrs.PlateCarree(), ylim = (-60, 80),\n",
    "                   cmap = 'reds', coastline = True, geo = True, levels = 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
