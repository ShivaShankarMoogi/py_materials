{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"http://www.nasa.gov/sites/all/themes/custom/nasatwo/images/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://github.com/astg606/py_materials/blob/master/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center><h1> <font color=\"red\">Reading MODIS hdf Files using pyhdf</font></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Jupyter notebook shows an example of how to use the **pyhdf**, **Numpy**, **Matplotlib**, and **Cartopy** Python packages to work with MODIS files in HDF4 format.  \n",
    "\n",
    "The main workflow steps are:\n",
    "- Open a MODIS HDF4 file\n",
    "- Read the global file metadata\n",
    "    - Recognize the file attribute\n",
    "    - Find names of variables and their attributes\n",
    "- Read dataset from file\n",
    "- Visualize satellite data on a map\n",
    "\n",
    "Write an application a read a collection of MODIS data files and plot a specific field within a specified region."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Primary References/Resources</font>\n",
    "\n",
    "- [Moderate Resolution Imaging Spectrometer (MODIS)](https://modis.gsfc.nasa.gov/data/)\n",
    "- [HDF-EOS Comprehensive Examples page](http://hdfeos.org/zoo/)\n",
    "- [How to read a MODIS HDF4 file using python and pyhdf ?](https://moonbooks.org/Articles/How-to-read-a-MODIS-HDF-file-using-python-/)\n",
    "- [SD (scientific dataset) API (pyhdf.SD)](http://fhs.github.io/pyhdf/modules/SD.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Import the Python Packages</font>\n",
    "\n",
    "Four Python packages (libraries)  used in this Notebook:\n",
    "- **pyhdf**: Read HDF4 files\n",
    "- **NumPy**: Perform array operations\n",
    "- **Matplotlib**: Make static plots (mainly two-dimensional)\n",
    "- **Cartopy**: Create maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.xarray\n",
    "import cartopy\n",
    "from cartopy import crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import cartopy.io.shapereader as shapereader\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhdf.SD import SD\n",
    "from pyhdf.SD import SDS\n",
    "from pyhdf.SD import SDC\n",
    "from pyhdf.SD import SDim\n",
    "from pyhdf.SD import SDAttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Version of Numpy:   {np.__version__}\")\n",
    "print(f\"Version of Cartopy: {cartopy.__version__}\")\n",
    "print(f\"Version of Xarray:  {xr.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">[MODIS](https://modis.gsfc.nasa.gov/)</font>\n",
    "\n",
    "#### MODIS Intrument\n",
    "MODIS (or Moderate Resolution Imaging Spectroradiometer) is a key instrument aboard the Terra and Aqua satellites. Terra's orbit around the Earth is timed so that it passes from north to south across the equator in the morning, while Aqua passes south to north over the equator in the afternoon. Terra MODIS and Aqua MODIS are viewing the entire Earth's surface every 1 to 2 days, acquiring data in 36 spectral bands, or groups of wavelengths. These data will improve our understanding of global dynamics and processes occurring on the land, in the oceans, and in the lower atmosphere. MODIS is playing a vital role in the development of validated, global, interactive Earth system models able to predict global change accurately enough to assist policy makers in making sound decisions concerning the protection of our environment.\n",
    "\n",
    "#### MODIS Data\n",
    "\n",
    "The MODIS instrument has a viewing swath width of 2,330 km and views the entire surface of the Earth every one to two days. Its detectors measure 36 spectral bands between 0.405 and 14.385 Âµm, and it acquires data at three spatial resolutions -- 250m, 500m, and 1,000m.\n",
    "\n",
    "The many data products derived from MODIS observations describe features of the land, oceans and the atmosphere that can be used for studies of processes and trends on local to global scales. MODIS products are available from several sources.  \n",
    "\n",
    "- [MODIS Level 1](http://ladsweb.nascom.nasa.gov/) and atmosphere products are available through the LAADS web.  \n",
    "- [Land Products](https://lpdaac.usgs.gov/) are available through the Land Processes DAAC at the U. S. Geological Survey EROS Data Center (EDC).  \n",
    "- [Cryosphere data products](http://nsidc.org/daac/modis/index.html) (snow and sea ice cover) are available from the National Snow and Ice Data Center (NSIDC) in Boulder, Colorado.  \n",
    "- [Ocean color products and sea surface temperature products](http://oceancolor.gsfc.nasa.gov/) along with information about these products are obtainable at the OCDPS at GSFC.  \n",
    "\n",
    "Users with an appropriate x-band receiving system may capture regional data directly from the spacecraft using the MODIS Direct Broadcast signal. \n",
    "\n",
    "#### MODIS File Naming Conventions\n",
    "- [MODIS Naming Conventions](https://lpdaac.usgs.gov/data/get-started-data/collection-overview/missions/modis-overview/#:~:text=MODIS%20Filenames,A2019159.)\n",
    "- [MODIS Level-2 Hierarchical Data Format (HDF)](https://modis-images.gsfc.nasa.gov/MOD07_L2/filename.html)\n",
    "- [MODIS/VIIRS Land Product Subsets](https://modis.ornl.gov/documentation.html)\n",
    "\n",
    "\n",
    "MODIS filenames follow a naming convention which gives useful information regarding the specific product. The filename `MOD09A1.A2006001.h08v05.005.2006012234657.hdf` indicates:\n",
    "\n",
    "- `MOD09A1`: Product Short Name\n",
    "- `A2006001`: Julian Date of Acquisition (A-YYYYDDD)\n",
    "- `h08v05`: Tile Identifier (horizontalXXverticalYY)\n",
    "- `005`: Collection Version\n",
    "- `2006012234567`: Julian Date of Production (YYYYDDDHHMMSS)\n",
    "- `hdf`: Data Format (HDF-EOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Accessing a Sample HDF4 Data Files</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Step 1: Identify the Location of the File</font>\n",
    "\n",
    "Directory where the MODIS files are located:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/jkouatch/myTasks/PythonTraining/ASTG606/Materials/sat_data/MODIS_Data/\"\n",
    "#data_dir = \"/tljh-data/sat_data/MODIS_Data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full path to the file names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.join(data_dir, \"MOD021KM.A2015013.1240.006.2015014140954.hdf\")\n",
    "geo_file_name = os.path.join(data_dir, \"MOD03.A2015013.1240.006.2015013194359.hdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name of the field of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = \"EV_Band26\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Step 2: Open the File</font>\n",
    "\n",
    "Opening files for reading:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid = SD(file_name, SDC.READ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Step 3: Obtain the File Attributes</font>\n",
    "\n",
    "Basic information on the files:\n",
    "\n",
    "- The first number indicates the number of datasets in the file (not to be confused w/ xarray datasets)\n",
    "- The second number indicates the number of attributes attached to the global file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Attributes\n",
    "\n",
    "- We can access the file attributes which hold important global metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_attrs = fid.attributes()\n",
    "pprint.pprint(file_attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, name in enumerate(file_attrs.keys(), start=1):\n",
    "    print(f\"{idx:>3} --> {name}: \\n\\t {file_attrs[name]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the datasets' names and basic info such as shape and dimension labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dts = fid.datasets()\n",
    "for index, name in enumerate(file_dts.keys(), start=1):\n",
    "    print(f\"{index:>3}- {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dts[field_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Step 4: Extract the Dataset</font>\n",
    "\n",
    "Let's assume that we want to extract data from the field `EV_Band26`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `select()` method from the `SD` class allows us to extract a dataset (object) given it's name or index number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds = fid.select(field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get basic information from the dataset:\n",
    "\n",
    "- The `info()` function in the `SDS` class allows us to get the dataset name, rank, dimension lengths, data type, and number of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the dataset attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = sample_ds.attributes()\n",
    "attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the data\n",
    "\n",
    "- We can retrieve and store the data itself as a NumPy array using the `get()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sample_ds.get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirms that the data has been stored as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Class Type: \", type(sample_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like any NumPy array, we can get the shape and dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to change the type from integer to float:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sample_data.astype(np.double)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Step 6: Restore the Data</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the dataset attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attrs = sample_ds.attributes(full=1)\n",
    "\n",
    "long_name = attrs[\"long_name\"][0]\n",
    "add_offset = attrs[\"radiance_offsets\"][0]\n",
    "_FillValue = attrs[\"_FillValue\"][0]\n",
    "scale_factor = attrs[\"radiance_scales\"][0]       \n",
    "valid_min = attrs[\"valid_range\"][0][0]        \n",
    "valid_max = attrs[\"valid_range\"][0][1]        \n",
    "units = attrs[\"radiance_units\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the attributes to restore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_data(data, scale_factor, add_offset,  _FillValue, \n",
    "                 valid_min, valid_max):\n",
    "    \"\"\"\n",
    "       Use the attributes to:\n",
    "        1- Select the values within the valid range\n",
    "        2- Mask the filled values\n",
    "        3- To apply the offset and scale to the data\n",
    "    \"\"\"\n",
    "    invalid = np.logical_or(data > valid_max, data < valid_min)\n",
    "    invalid = np.logical_or(invalid, data == _FillValue)\n",
    "    data[invalid] = np.nan\n",
    "    data -= add_offset\n",
    "    data *= scale_factor\n",
    "    data = np.ma.masked_array(data, np.isnan(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = restore_data(sample_data, \n",
    "                    scale_factor, add_offset,  \n",
    "                    _FillValue, \n",
    "                    valid_min, valid_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.min(), data.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View the data as an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots (figsize = (8,8))\n",
    "im = ax.imshow(data)\n",
    "plt.colorbar(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Step 7: Read Geolocation Dataset from MOD03 Product</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_fid = SD(geo_file_name, SDC.READ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_fid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_file_attrs = geo_fid.attributes()\n",
    "for index, name in enumerate(geo_file_attrs.keys(), start=1):\n",
    "    print(index, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_file_dts = geo_fid.datasets()\n",
    "for index, name in enumerate(geo_file_dts.keys(), start=1):\n",
    "    print(index, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = geo_fid.select('Latitude').get()\n",
    "lats.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = geo_fid.select('Longitude').get()\n",
    "lons.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find middle location:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_m = np.nanmean(lats)\n",
    "lon_m = np.nanmean(lons) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Step 8: Use Cartopy to Plot the Data</font>\n",
    "\n",
    "The reference plot can be seen at:\n",
    "\n",
    "[https://hdfeos.org/zoo/LAADS/MOD021KM.A2015013.1240.006.2015014140954.hdf.py.png](https://hdfeos.org/zoo/LAADS/MOD021KM.A2015013.1240.006.2015014140954.hdf.py.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map_projection = ccrs.PlateCarree()\n",
    "map_projection = ccrs.LambertAzimuthalEqualArea(\n",
    "                      central_longitude=lon_m, \n",
    "                      central_latitude=lat_m\n",
    "                )\n",
    "data_transform = ccrs.PlateCarree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the figure object with the dimansion of the figure\n",
    "subplot_kw = dict(projection=map_projection)\n",
    "fig, ax = plt.subplots(1, 1,\n",
    "                       figsize=(12, 9),\n",
    "                       subplot_kw=subplot_kw)\n",
    "\n",
    "im = ax.pcolormesh(lons, lats, data, transform=data_transform)\n",
    "\n",
    "# Map features\n",
    "map_res = '110m'\n",
    "ax.coastlines(resolution=map_res, linewidth=1.0)\n",
    "ax.add_feature(cfeature.BORDERS, edgecolor='black', linewidth=1.0)\n",
    "\n",
    "# Colorbar\n",
    "cbar = fig.colorbar(im, ax=ax,  orientation=\"vertical\", shrink=0.95)\n",
    "cbar.ax.tick_params(labelsize=15)\n",
    "cbar.set_label(units, labelpad=+1)\n",
    "\n",
    "# ---> Ticks and labels\n",
    "gl = ax.gridlines(\n",
    "    draw_labels=True, \n",
    "    linewidth=2, color='gray', \n",
    "    alpha=0.5, linestyle='--'\n",
    ")\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Application</font>\n",
    "\n",
    "- Takes a collection of MODIS data files\n",
    "- Select a field (contained in the files)\n",
    "- Loop over the files:\n",
    "     - Select only the files which horizontal coverage falls within a prescribed latitude range\n",
    "     - Perform a global plot on the selected field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Test to Create a Global Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_projection = ccrs.PlateCarree()\n",
    "data_transform = ccrs.PlateCarree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_globe(map_res, map_projection):\n",
    "    \"\"\"\n",
    "    Map the entire globe, draw continents/countries, \n",
    "    longitude/latitude lines.\n",
    "    Paramters\n",
    "    ---------\n",
    "    map_res : str\n",
    "        Resolution ('110m', '50m', '10m') of the Cartopy features.\n",
    "    Returns\n",
    "    -------\n",
    "    fig, ax : Matplotlib figure and axes\n",
    "    \"\"\"\n",
    "    subplot_kw = dict(projection=map_projection)\n",
    "    fig, ax = plt.subplots(1, 1,\n",
    "                       figsize=(15, 9),\n",
    "                       subplot_kw=subplot_kw)\n",
    "\n",
    "    # Consider the entire globe\n",
    "    ax.set_extent([-180, 180, -90, 90], ccrs.PlateCarree())\n",
    "\n",
    "    # Map features\n",
    "    #map_res = '110m'\n",
    "    ax.coastlines(resolution=map_res, linewidth=1.0)\n",
    "    ax.add_feature(cfeature.LAND, edgecolor='black', linewidth=1.0)\n",
    "    ax.add_feature(cfeature.BORDERS, edgecolor='black', linewidth=1.0)\n",
    "\n",
    "    # ---> Ticks and labels\n",
    "    gl = ax.gridlines(crs=map_projection, draw_labels=True,\n",
    "                  linewidth=2, color='gray', alpha=0.5, linestyle='--')\n",
    "    gl.xlabels_top = False\n",
    "    gl.ylabels_right = False\n",
    "\n",
    "    lon_formatter = LongitudeFormatter(zero_direction_label=True)\n",
    "    lat_formatter = LatitudeFormatter()\n",
    "    ax.xaxis.set_major_formatter(lon_formatter)\n",
    "    ax.yaxis.set_major_formatter(lat_formatter)\n",
    "    ax.xaxis.label.set_size(20)\n",
    "    ax.yaxis.label.set_size(20)\n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_res = '110m'\n",
    "fig, ax = map_globe(map_res, map_projection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Field of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATAFIELD_NAME = 'LST'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latidude range of the area of interest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lat = -55.0\n",
    "max_lat =  60.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the list of possible files to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = glob.glob(data_dir+'MOD11_*.hdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each of the data file (starting with `MOD11`) comes if its corresponding geolocation file (starting with  `MOD03`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_geo_files = list()\n",
    "for fname in list_files:\n",
    "    basename = os.path.basename(fname)\n",
    "    geo_fname = glob.glob(data_dir+'MOD03.'+basename[9:26]+'*hdf')[0]\n",
    "    list_geo_files.append(geo_fname)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list_geo_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_geo_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname, geo_fname in zip(list_files, list_geo_files):\n",
    "    print(f\"{os.path.basename(fname)} -> {os.path.basename(geo_fname)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_res = '110m'\n",
    "fig, ax = map_globe(map_res, map_projection)\n",
    "\n",
    "# Loop over the files and do the plot:\n",
    "for fname, geo_fname in zip(list_files, list_geo_files):\n",
    "    hdf_geo = SD(geo_fname, SDC.READ)\n",
    "    \n",
    "    # Extract the latitude data\n",
    "    latitude = hdf_geo.select('Latitude')\n",
    "    lat = latitude[:,:]\n",
    "\n",
    "    # Only consider the the data file which horizontal coverage \n",
    "    # overlaps with the prescribed latitude rangnge\n",
    "    if np.min(lat)<min_lat or np.max(lat)>max_lat:\n",
    "        print(f\"Rejecting the files: \\n\\t {os.path.basename(fname)} \\n\\t {os.path.basename(geo_fname)}\")\n",
    "        continue  # Move to the next file\n",
    "\n",
    "    longitude = hdf_geo.select('Longitude')\n",
    "    lon = longitude[:,:]\n",
    "\n",
    "    print(f\"Processing the files: \\n\\t {os.path.basename(fname)} \\n\\t {os.path.basename(geo_fname)}\")\n",
    "\n",
    "    # Read dataset.\n",
    "    hdf = SD(fname, SDC.READ)\n",
    "\n",
    "    data2D = hdf.select(DATAFIELD_NAME)\n",
    "    data = data2D[:,:].astype(np.double)\n",
    "\n",
    "    # Get the dataset attributes\n",
    "    attrs = data2D.attributes(full=1)\n",
    "    long_name = attrs[\"long_name\"][0]\n",
    "    add_offset = attrs[\"add_offset\"][0]\n",
    "    _FillValue = attrs[\"_FillValue\"][0]\n",
    "    scale_factor = attrs[\"scale_factor\"][0]\n",
    "    valid_min = attrs[\"valid_range\"][0][0]\n",
    "    valid_max = attrs[\"valid_range\"][0][1]\n",
    "    units = attrs[\"units\"][0]\n",
    "\n",
    "    data = restore_data(data, scale_factor, add_offset,  _FillValue,\n",
    "                        valid_min, valid_max)\n",
    "\n",
    "    # Plot the data\n",
    "    im = ax.pcolormesh(lon, lat, data, transform=map_projection)\n",
    "    \n",
    "# Add a colorbar\n",
    "cbar = fig.colorbar(im, ax=ax,  orientation=\"horizontal\", shrink=0.75)\n",
    "cbar.ax.tick_params(labelsize=15)\n",
    "cbar.set_label(units, labelpad=+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">L4 Level File</font>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_L3 = os.path.join(data_dir, \n",
    "                        \"MOD08_D3.A2020126.061.2020127085602.hdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid = SD(file_name_L3, SDC.READ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, name in enumerate(file_attrs.keys(), start=1):\n",
    "    print(f\"{idx:>3} --> {name}: \\n\\t {file_attrs[name]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dts = fid.datasets()\n",
    "for index, name in enumerate(file_dts.keys(), start=1):\n",
    "    print(f\"{index:>3}- {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latitude and Longitude Grid Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = fid.select(\"XDim\").get()\n",
    "lats = fid.select(\"YDim\").get()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract `Cirrus_Fraction_Infrared`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_name = \"Cirrus_Fraction_Infrared\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfi_ds = fid.select(field_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_attribute_value(sample_ds, attr_name):\n",
    "    '''\n",
    "    Obtain the value of a specified attribute in a dataset.\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    sample_ds : SDS object\n",
    "    attr_name : str\n",
    "         Attribute name    \n",
    "    \n",
    "    Returns\n",
    "    --------\n",
    "    value: float, int, str, list\n",
    "         Value of the attribute. If attribute not available, None.\n",
    "    '''\n",
    "    for key, value in sample_ds.attributes().items():\n",
    "        if key == attr_name:\n",
    "            return value \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_data(sample_ds):\n",
    "    '''\n",
    "    Restore the data given the dataset attribute\n",
    "    Parameter(s): SDS object\n",
    "    Return Type(s): NumPy array\n",
    "    Function: restores data of a given dataset object\n",
    "    '''\n",
    "    _FillValue = get_ds_attribute_value(sample_ds, '_FillValue')\n",
    "    scale_factor = get_ds_attribute_value(sample_ds, 'scale_factor')\n",
    "    add_offset = get_ds_attribute_value(sample_ds, 'add_offset')\n",
    "    valid_range = get_ds_attribute_value(sample_ds, 'valid_range')\n",
    "    \n",
    "    data = sample_ds.get().astype('float')\n",
    "    \n",
    "    if valid_range:\n",
    "        valid_min, valid_max = valid_range[0], valid_range[1]\n",
    "        invalid = np.logical_or(data > valid_max, data < valid_min)\n",
    "    \n",
    "    #data[invalid] = np.nan\n",
    "    #data = np.where(data != _FillValue, data, np.nan)\n",
    "    \n",
    "    if _FillValue:\n",
    "        if valid_range:\n",
    "            invalid = np.logical_or(invalid, data == _FillValue)\n",
    "            data[invalid] = np.nan\n",
    "        else:\n",
    "            data = np.where(data != _FillValue, data, np.nan)\n",
    "    \n",
    "    if add_offset:\n",
    "        data -= add_offset\n",
    "    if scale_factor:\n",
    "        data *= scale_factor\n",
    "    data = np.ma.masked_array(data, np.isnan(data))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = restore_data(cfi_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map `Cirrus_Fraction_Infrared`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = get_ds_attribute_value(cfi_ds, 'units')\n",
    "long_name = get_ds_attribute_value(cfi_ds, 'long_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_projection = ccrs.PlateCarree()\n",
    "data_transform = ccrs.PlateCarree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplot_kw = dict(projection=map_projection)\n",
    "fig, ax = plt.subplots(1, 1,\n",
    "                       figsize=(12, 9),\n",
    "                       subplot_kw=subplot_kw)\n",
    "\n",
    "im = ax.pcolormesh(lons, lats, data, transform=data_transform, cmap=\"hsv\")\n",
    "\n",
    "# Map features\n",
    "map_res = '110m'\n",
    "ax.coastlines(resolution=map_res, linewidth=1.0)\n",
    "#ax.add_feature(cfeature.BORDERS, edgecolor='black', linewidth=1.0)\n",
    "\n",
    "# Colorbar\n",
    "cbar = fig.colorbar(im, ax=ax,  orientation=\"vertical\", shrink=0.55)\n",
    "cbar.ax.tick_params(labelsize=15)\n",
    "cbar.set_label(units, labelpad=+1)\n",
    "\n",
    "# ---> Ticks and labels\n",
    "gl = ax.gridlines(\n",
    "    draw_labels=True, \n",
    "    linewidth=2, color='gray', \n",
    "    alpha=0.5, linestyle='--'\n",
    ")\n",
    "gl.xlabels_top = False\n",
    "gl.ylabels_right = False\n",
    "ax.set_title(long_name, fontsize=10);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
