{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><img src=\"http://www.nasa.gov/sites/all/themes/custom/nasatwo/images/nasa-logo.svg\" width=\"100\"/> </td>\n",
    "     <td><img src=\"https://github.com/astg606/py_materials/blob/master/logos/ASTG_logo.png?raw=true\" width=\"80\"/> </td>\n",
    "     <td> <img src=\"https://www.nccs.nasa.gov/sites/default/files/NCCS_Logo_0.png\" width=\"130\"/> </td>\n",
    "    </tr>\n",
    "</table>\n",
    "</center>\n",
    "\n",
    "        \n",
    "<center>\n",
    "<h1><font color= \"blue\" size=\"+3\">ASTG Python Courses</font></h1>\n",
    "</center>\n",
    "\n",
    "---\n",
    "\n",
    "<center><h1> <font color=\"red\">Reading LANDSAT hdf Files using pyhdf</font></h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Primary References/Resources</font>\n",
    "\n",
    "- https://moonbooks.org/Articles/How-to-read-a-MODIS-HDF-file-using-python-/\n",
    "- http://fhs.github.io/pyhdf/modules/SD.html "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Statements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import hvplot.xarray\n",
    "from cartopy import crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhdf.SD import SD\n",
    "from pyhdf.SD import SDS\n",
    "from pyhdf.SD import SDC\n",
    "from pyhdf.SD import SDim\n",
    "from pyhdf.SD import SDAttr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toggles off alphabetical sorting\n",
    "pprint.sorted = lambda x, key=None:x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">LANDSAT File Name Convention</font>\n",
    "\n",
    "Details on the naming convention can be found in:\n",
    "\n",
    "https://gisgeography.com/landsat-file-naming-convention/\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Accessing a Sample HDF4 Data Files</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"/Users/jkouatch/myTasks/PythonTraining/ASTG606/Materials/sat_data/LANDSAT_Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = os.path.join(data_dir, \"LT50830152011198GLC00.hdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"> Opening a File</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening file for reading\n",
    "fid = SD(file_name, SDC.READ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some file information only work if attributes exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Author:\", fid.author)\n",
    "# print(\"Priority:\", fid.priority)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic information on the files:\n",
    "\n",
    "- The first number indicates the number of datasets in the file (not to be confused w/ xarray datasets)\n",
    "- The second number indicates the number of attributes attached to the global file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### File Attributes\n",
    "\n",
    "- We can access the file attributes which hold important global metadata.\n",
    "- Some notable ones are the data provider, satellite name and instrument, coordinate boundaries, and structural metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file_attrs = fid.attributes()\n",
    "pprint.pprint(file_attrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the datasets' names and basic info such as shape and dimension labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dts = fid.datasets()\n",
    "pprint.pprint(file_dts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, name in enumerate(file_dts.keys(), start=1):\n",
    "    print(index, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Data Extraction as NumPy Arrays</font>\n",
    "\n",
    "Let's assume that we want to extract data from the field `sr_band4`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `select()` method from the `SD` class allows us to extract a dataset (object) given it's name or index number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds = fid.select('sr_band4') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get basic information from the dataset:\n",
    "\n",
    "- The `info()` function in the `SDS` class allows us to get the dataset name, rank (or level with file-leve being rank 1), dimension lengths, data type, and number of attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_ds.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the dataset attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_attrs = sample_ds.attributes()\n",
    "ds_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important information such as `fill values`, `scale factors`, and `offset values` are found in dataset attributes and will be important to fully restoring the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default values (also a reset if testing different datasets/variables)\n",
    "fill = None\n",
    "scale = 1\n",
    "offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in sample_ds.attributes().items():\n",
    "    if key == '_FillValue':\n",
    "        fill = value  \n",
    "    if key == 'scale_factor':\n",
    "        scale = value\n",
    "    if key == 'add_offset':\n",
    "        offset = value\n",
    "# data = data * scale + offset\n",
    "    \n",
    "print('Fill Value:', fill)\n",
    "print('Scale Factor:', scale)\n",
    "print('Offset:', offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract the data\n",
    "\n",
    "- We can retrieve and store the data itself as a NumPy array using the `get()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = sample_ds.get() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirms that the data has been stored as a NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset Class Type: \", type(sample_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like any NumPy array, we can get the shape and dtype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DATA TYPES\n",
    "\n",
    "0 - SDC.UNLIMITED: dimensions only; they can grow dynamically\n",
    "\n",
    "3 - SDC.UCHAR; SDC.UCHAR8: unsigned 8-bit integer\n",
    "\n",
    "4 - SDC.CHAR; SDC.CHAR8: 8-bit character\n",
    "\n",
    "5 - SDC.FLOAT32: 32-bit floating point\n",
    "\n",
    "6 - SDC.FLOAT64: 64-bit floating point\n",
    "\n",
    "20 - SDC.INT8: signed 8-bit integer\n",
    "\n",
    "21 - SDC.UINT8: unsigned 8-bit integer\n",
    "\n",
    "22 - SDC.INT16: signed 16-bit integer\n",
    "\n",
    "23 - SDC.UINT16: unsigned 16-bit integer\n",
    "\n",
    "24 - SDC.INT32: signed 32-bit integer\n",
    "\n",
    "25 - SDC.UINT32: unsigned 32-bit integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\">Attributes</font>\n",
    "\n",
    "There are three levels of attributes:\n",
    "\n",
    "- **File** or **global** attributes\n",
    "- **Dataset** or **data** attributes\n",
    "- **Dimension** attributes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dimensions\n",
    "\n",
    "- From the `SDS` class, we can access the dimension names and sizes using the `dimensions()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dims = sample_ds.dimensions()\n",
    "ds_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is nice, the dictionary above does not allow us to access actual dimension objects and the other information that they may hold. To access the objects, we can use the `dim()` function from the `SDS` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_dims = list()   \n",
    "\n",
    "for i in range(len(ds_dims)):\n",
    "    sample_dims.append(sample_ds.dim(i))\n",
    "    \n",
    "sample_dims = tuple(sample_dims)\n",
    "\n",
    "sample_dims   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we can see that we can access not only the labels and size but also the units, scale data type, and number of attributes. We can even access the attributes similarly to the dataset object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(sample_dims)):\n",
    "    print(f\"Dimension {i+1}\")\n",
    "    print(\"\\tInfo:\", sample_dims[i].info())\n",
    "    print(\"\\tLength:\", sample_dims[i].length())\n",
    "    print(\"\\tAttributes: \", sample_dims[i].attributes())\n",
    "    \n",
    "    # You can access other dim attrs if they exist by this given struture: dim1.attr_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** * Note from the data type table that dimensions exclusively may have the value 0 or a `SDC.UNLIMITED` data type. This just means that they can grow dynamically **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pyHDF, it is possible that coordinates (known as dimension scales) are actually stored as datasets. Thankfully, the `SDS` class provides the `iscoordvar()` function to determine that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bool(sample_ds.iscoordvar()))\n",
    "\n",
    "# If there was a scale, it would be accessible via: dim1.getscale()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try to traverse through all the datasets and see if one of them holds coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_sets = list()   # Will hold datasets suspected to be coordinates\n",
    "\n",
    "for i in range(len(fid.datasets())):\n",
    "    ds = fid.select(i)\n",
    "    if ds.iscoordvar():\n",
    "        coord_sets.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible that some coordinate information is stored as a file attribute. If we go back once more to our global attribute dictionary, we can see some keys such as corner and bounding coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pprint.pprint(fid.attributes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then traverse through it and extract and attributes that may be related to the coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_attrs = {}   # Will hold coordinate-related attributes\n",
    "for key, value in fid.attributes().items():\n",
    "    if 'coordinate' in key.lower() or 'latlong' in key.lower():\n",
    "        coord_attrs[key] = value\n",
    "\n",
    "coord_attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at these attributes, it would be much easier to work with our bounding coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now go back to our datasets, we can see that thankfully, they all have the same shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 1\n",
    "for vals in fid.datasets().values():\n",
    "    print(f\"Dataset {count} Shape:\", vals[0:2])\n",
    "    count += 1\n",
    "    shape = vals[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the bounding coordinates and the shape, we can artificially create our full coordinates; however, this is under the assumption that the datasets truly align with this artificial system. This means that we can't confirm its accuracy.\n",
    "\n",
    "The first step would be to assign our boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in coord_attrs.keys():\n",
    "    if 'north' in key.lower():\n",
    "        latN = coord_attrs[key]\n",
    "    if 'south' in key.lower():\n",
    "        latS = coord_attrs[key]\n",
    "    if 'east' in key.lower():\n",
    "        lonE = coord_attrs[key]\n",
    "    if 'west' in key.lower():\n",
    "        lonW = coord_attrs[key]\n",
    "\n",
    "print(\"North:\", latN)\n",
    "print(\"South:\", latS)\n",
    "print(\"East:\", lonE)\n",
    "print(\"West:\", lonW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we would create our spacing using the dataset shapes and boundaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating our coords. 'lats' can be substituted for 'y' and 'lons' for 'x'\n",
    "lat_space = (latN - latS) / shape[0]\n",
    "lon_space = (lonE - lonW) / shape[1]\n",
    "\n",
    "print(lat_space, \"|\", lon_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can finally create our coordinates!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lats = np.linspace(latS, latN, shape[0])\n",
    "lons = np.linspace(lonW, lonE, shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Latitudes:\\n', lats)\n",
    "print('Longitudes:\\n', lons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll now close our file reader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fid.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Conversion to XArray DataArrays and Datasets</font>\n",
    "\n",
    "Now that we've been able to get all of the necessary information to create an Xarray Dataset, we can start!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fid(sample_file):\n",
    "    \"\"\"\n",
    "        Parameter(s): a file name (str)\n",
    "        Return Type(s): an SD object (file identifier)\n",
    "        Function: returns our file reader object\n",
    "    \"\"\"\n",
    "    sample_fid = SD(sample_file, SDC.READ)\n",
    "    return sample_fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fill(sample_ds):\n",
    "    '''\n",
    "       Parameter(s): SDS object\n",
    "       Return Type(s): float, int, or None\n",
    "       Function: returns fill value of a given dataset object\n",
    "    '''\n",
    "    for key, value in sample_ds.attributes().items():\n",
    "        if key == '_FillValue':\n",
    "            return value \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scale(sample_ds):\n",
    "    '''\n",
    "       Parameter(s): SDS object\n",
    "       Return Type(s): float, int, or None\n",
    "       Function: returns scale factor of a given dataset object\n",
    "    '''\n",
    "    for key, value in sample_ds.attributes().items():\n",
    "        if key == 'scale_factor':\n",
    "            return value \n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_offset(sample_ds):\n",
    "    '''\n",
    "        Parameter(s): SDS object\n",
    "        Return Type(s): float, int, or None\n",
    "        Function: returns offset value of a given dataset object\n",
    "    '''\n",
    "    for key, value in sample_ds.attributes().items():\n",
    "        if key == 'add_offset':\n",
    "            return value \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def restore_data(sample_ds):\n",
    "    '''\n",
    "       Parameter(s): SDS object\n",
    "       Return Type(s): NumPy array\n",
    "       Function: restores data of a given dataset object\n",
    "    '''\n",
    "    fill = get_fill(sample_ds)\n",
    "    scale = get_scale(sample_ds)\n",
    "    offset = get_offset(sample_ds)\n",
    "    \n",
    "    data = sample_ds.get()#.astype('float')\n",
    "    \n",
    "    data = np.where(data != fill, data, np.nan)\n",
    "    data *= scale\n",
    "    data += offset\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dims(sample_ds):\n",
    "    '''\n",
    "       Parameter(s): SDS object\n",
    "       Return Type(s): Python list of SDim objects\n",
    "       Function: returns dimension objects of a given dataset object\n",
    "    '''\n",
    "    sample_dims = []   # Will actually hold dimension objects\n",
    "    \n",
    "    for i in range(len(sample_ds.dimensions())):\n",
    "        sample_dims.append(sample_ds.dim(i))\n",
    "        \n",
    "    return sample_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dim_attrs(dim):\n",
    "    '''\n",
    "        Parameter(s): SDim object\n",
    "        Return Type(s): Python Dict\n",
    "        Function: returns attributes of a given dimension object\n",
    "    '''\n",
    "    attrs = dict()\n",
    "    \n",
    "    attrs['Given Name'] = dim.info()[0]\n",
    "    attrs['dtype'] = dim.info()[2]\n",
    "    attrs.update(dim.attributes())   # Adds other unknown attributes\n",
    "    \n",
    "    return attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dims_attrs(ds):\n",
    "    dims_attrs = dict()\n",
    "    dims = get_dims(ds)\n",
    "    \n",
    "    for dim in dims:\n",
    "        if dim.info()[0] == 'YDim':\n",
    "            dims_attrs['lat'] = get_dim_attrs(dim)\n",
    "        elif dim.info()[0] == 'XDim':\n",
    "            dims_attrs['lon'] = get_dim_attrs(dim)\n",
    "            \n",
    "    return dims_attrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_fid_coords(sample_fid):\n",
    "    '''\n",
    "       Accessing File-level Coords\n",
    "       Parameter(s): SD object\n",
    "       Return Type(s): boolean\n",
    "       Function: returns false if there are no file-level coords and true if there are\n",
    "       ** Should be modified to return list of file-level coords if there are any\n",
    "    '''\n",
    "    coord_sets = list()\n",
    "\n",
    "    for i in range(len(sample_fid.datasets())):\n",
    "        sample_ds = sample_fid.select(i)\n",
    "        if bool(sample_ds.iscoordvar()):\n",
    "            coord_sets.append(sample_ds)\n",
    "\n",
    "    if len(coord_sets) > 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coord_bounds(sample_fid):\n",
    "    '''\n",
    "       Parameter(s): SD object\n",
    "       Return Type(s): Python dict of String keys and numeric items\n",
    "       Function: returns coord boundaries from file-level attrs to construct coords at dataset level\n",
    "    '''\n",
    "    coord_attrs = {}    \n",
    "    # Gets our coordinate-related attributes\n",
    "    for key, value in sample_fid.attributes().items():\n",
    "        if 'coordinate' in key.lower():\n",
    "            coord_attrs[key] = value \n",
    "        \n",
    "    coord_bounds = {}\n",
    "    # Gets our coordinate bounds\n",
    "    for key in coord_attrs.keys():\n",
    "        if 'north' in key.lower():\n",
    "            coord_bounds['latN'] = coord_attrs[key]\n",
    "        if 'south' in key.lower():\n",
    "            coord_bounds['latS'] = coord_attrs[key]\n",
    "        if 'east' in key.lower():\n",
    "            coord_bounds['lonE'] = coord_attrs[key]\n",
    "        if 'west' in key.lower():\n",
    "            coord_bounds['lonW'] = coord_attrs[key]    \n",
    "    \n",
    "    return coord_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ds_coords(sample_fid, sample_ds): \n",
    "    '''\n",
    "       Accessing Dataset-level Coords\n",
    "       Parameter(s): an SD and an SDS object\n",
    "       Return Type(s): Python dict of String keys and NumPy array items\n",
    "       Function: returns constructed dataset given the file ID object and a particular dataset\n",
    "    '''\n",
    "    sample_bounds = get_coord_bounds(sample_fid)\n",
    "    \n",
    "    latN = sample_bounds['latN']\n",
    "    latS = sample_bounds['latS']\n",
    "    lonE = sample_bounds['lonE']\n",
    "    lonW = sample_bounds['lonW']\n",
    "    \n",
    "    lat_shape = sample_ds.dimensions()['YDim']\n",
    "    lon_shape = sample_ds.dimensions()['XDim']\n",
    "    \n",
    "    if isinstance(sample_bounds, dict):   # Have to configure dataset coords\n",
    "        lat_space = (latN - latS) / lat_shape\n",
    "        lon_space = (lonE - lonW) / lon_shape\n",
    "        \n",
    "        lats = np.linspace(latS, latN + lat_space, lat_shape)\n",
    "        lons = np.linspace(lonW, lonE + lon_space, lon_shape)\n",
    "        \n",
    "        sample_coords = {'lats': lats, 'lons': lons}\n",
    "        return sample_coords\n",
    "        \n",
    "    #else:   # Coords already set at file level\n",
    "        #return sample_bounds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(file):\n",
    "    '''\n",
    "       Creating our XArray Dataset:\n",
    "       Parameter(s): file name (str)\n",
    "       Return Type(s): XArray Dataset\n",
    "       Function: reads a LANDSAT HDF4 file and returns an XArray dataset\n",
    "    '''\n",
    "    fid = get_fid(file)\n",
    "    \n",
    "    if get_fid_coords(fid):   # File-level coords exist\n",
    "        pass\n",
    "    else:\n",
    "        fid_coords = False    # File-level coords do not exist   \n",
    "    \n",
    "    xr_ds = xr.Dataset()\n",
    "    \n",
    "    for name in fid.datasets().keys():\n",
    "        ds = fid.select(name)\n",
    "        \n",
    "        coords_dict = get_ds_coords(fid, ds)\n",
    "        lats = coords_dict['lats']\n",
    "        lons = coords_dict['lons']\n",
    "        \n",
    "        xr_ds[name] = xr.DataArray(restore_data(ds), coords = [lats, lons], dims = ['lat', 'lon'])\n",
    "        \n",
    "        xr_ds[name].attrs = ds.attributes()\n",
    "        \n",
    "        dims = get_dims(ds)\n",
    "        for dim in dims:\n",
    "            if dim.info()[0] == 'YDim':\n",
    "                xr_ds[name].lat.attrs = get_dim_attrs(dim)\n",
    "            elif dim.info()[0] == 'XDim':\n",
    "                xr_ds[name].lon.attrs = get_dim_attrs(dim)\n",
    "    \n",
    "    xr_ds.attrs = fid.attributes()\n",
    "    \n",
    "    fid.end()\n",
    "    return xr_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1_ds = read_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Plotting Our Data</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1_MB = file1_ds.nbytes / 1000000\n",
    "\n",
    "file1_MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = file1_ds['toa_band6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic `matplotlib` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic `hvPlot` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1.hvplot()   # Doesn't work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An intermediate `hvPlot` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1.hvplot.quadmesh('lon', 'lat', xlim = (-172.5, -166.75), ylim = (63, 65.3), geo = True, project = True,\n",
    "                    rasterize = True, projection = ccrs.PlateCarree(), features = ['borders'], coastline = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2_ds = read_file(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2_MB = file2_ds.nbytes / 1000000\n",
    "\n",
    "file2_MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2 = file2_ds['toa_band6']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic `matplotlib` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic `hvPlot` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var2.hvplot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An intermediate `hvPlot` plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var1.hvplot.contourf('lon', 'lat', \n",
    "                     xlim = (-172.5, -166.75), \n",
    "                     ylim = (63, 65.3), \n",
    "                     geo = True, levels = 10,\n",
    "                    cmap = 'plasma', \n",
    "                     projection = ccrs.PlateCarree(), \n",
    "                     features = ['borders'], coastline = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
